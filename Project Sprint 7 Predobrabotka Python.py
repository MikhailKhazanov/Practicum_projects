#!/usr/bin/env python
# coding: utf-8

# # Проект спринта 7. Секреты темнолесья. Предобработка данных в Python.
# 
# - Автор: Хазанов Михаил
# - Дата: 30.01.2025

# ### Цели и задачи проекта
# 
# <font color='#777778'>Перечислите цель проекта и задачи, которые вы решаете. Для этого можно использовать описание проекта, но полезнее будет сформулировать основную цель проекта самостоятельно.</font>
# 
# Цель - помочь коллегам из «Секретов Темнолесья» изучить развитие игровой индустрии.
# Задачи - ознакомиться с данными, проверить их корректность и провести предобработку, получив необходимый срез данных.
# Перед анализом необходимо дополнительно сделать следующее:
# * Отобрать данные по времени выхода игры. Вам нужен период с 2000 по 2013 год включительно.
# * Категоризовать игры по оценкам пользователей и экспертов. Выделите три категории:
# -- высокая оценка — с оценкой от 8 до 10 и от 80 до 100, включая правые границы интервалов.
# -- средняя оценка — с оценкой от 3 до 8 и от 30 до 80, не включая правые границы интервалов.
# -- низкая оценка — с оценкой от 0 до 3 и от 0 до 30, не включая правые границы интервалов.
# * Выделить топ-7 платформ по количеству игр, выпущенных за весь требуемый период.

# ### Описание данных
# 
# <font color='#777778'>Здесь приведите описание данных.</font>
# 
# Данные /datasets/new_games.csv содержат информацию о продажах игр разных жанров и платформ, а также пользовательские и экспертные оценки игр:
# - Name — название игры.
# - Platform — название платформы.
# - Year of Release — год выпуска игры.
# - Genre — жанр игры.
# - NA sales — продажи в Северной Америке (в миллионах проданных копий).
# - EU sales — продажи в Европе (в миллионах проданных копий).
# - JP sales — продажи в Японии (в миллионах проданных копий).
# - Other sales — продажи в других странах (в миллионах проданных копий).
# - Critic Score — оценка критиков (от 0 до 100).
# - User Score — оценка пользователей (от 0 до 10).
# - Rating — рейтинг организации ESRB (англ. Entertainment Software Rating Board). Эта ассоциация определяет рейтинг компьютерных игр и присваивает им подходящую возрастную категорию.

# ### Содержимое проекта
# 
# <font color='#777778'>Перечислите основные шаги проекта или напишите оглавление. Используйте описание проекта, чтобы зафиксировать основные шаги.</font>
# 
# * Загрузка данных и знакомство с ними.
# * Проверка ошибок в данных и их предобработка.
# * Фильтрация данных.
# * Категоризация данных.
# * Итоговый вывод.
# 
# ---

# ## 1. Загрузка данных и знакомство с ними
# 
# - Загрузите необходимые библиотеки Python и данные датасета `/datasets/new_games.csv`.
# 

# In[1]:


# Пустые ячейки после каждого задания — примерное пространство для работы.
# Вы можете свободно добавлять или удалять ячейки по своему усмотрению в зависимости от логики и объёма работы.

# Импортируем библиотеку pandas
import pandas as pd

# Выгружаем hotel_dataset.csv в датафрейм
df = pd.read_csv('https://code.s3.yandex.net//datasets/new_games.csv')


# In[2]:


df


# - Познакомьтесь с данными: выведите первые строки и результат метода `info()`.
# 

# In[5]:



# Смотрим общую информацию, ненулевые строчки
df.info()


# In[6]:



# Смотрим общую информацию, ненулевые строчки
df.head(15)


# In[7]:


# Подсчитываем количество пропусков в каждом столбце
missing_counts = df.isna().sum()

# Рассчитываем долю пропусков
missing_part = missing_counts / len(df)

# Создаем датафрейм с результатами
missing_data = pd.DataFrame({'Количество пропусков': missing_counts, 'Доля пропусков': missing_part})
missing_data


# - Сделайте вывод о полученных данных: данные какого объёма вам предоставили, соответствуют ли они описанию, встречаются ли в них пропуски, используются ли верные типы данных.
# - Отметьте другие особенности данных, которые вы обнаружили и на которые стоит обратить внимание при предобработке. Например, вы можете проверить названия столбцов: все ли названия отражают содержимое данных и прописаны в удобном для работы виде.

# <font color='#777778'>Используйте ячейки типа Markdown для промежуточных выводов и расширенных комментариев к действиям с данными. </font>

# В наших данных 16956 строк и 11 столбцов. 4 столбца находятся в вещественном формате и 7 в формате object. Самое большое количество пропусков хранится в столбцах 'Critic Score' - 51.4%, 'User Score' - 40.1%, 'Rating' - 40.5%. В типе данных год надо привести к целочисленному значению int, оценку пользователя - к float
# 

# Названия столбцов написаны корректно (для меня). Все на английском языке, при необходимости можем перевести все на русский.

# ---
# 
# ## 2.  Проверка ошибок в данных и их предобработка
# 
# 
# ### 2.1. Названия, или метки, столбцов датафрейма
# 
# - Выведите на экран названия всех столбцов датафрейма и проверьте их стиль написания.
# - Приведите все столбцы к стилю snake case. Названия должны быть в нижнем регистре, а вместо пробелов — подчёркивания.

# In[8]:



# Выводим названия всех столбцов
column_all = df.columns.tolist()
column_all


# In[9]:




# Приведение названий столбцов к стилю snake case
# Заменяем пробелы на нижние подчеркивания в названиях столбцов
df.columns = df.columns.str.replace(' ', '_')

# Приводим все названия столбцов к нижнему регистру
df.columns = df.columns.str.lower()

# Выводим обновленные названия столбцов
new_columns = df.columns.tolist()
new_columns


# In[ ]:






# ### 2.2. Типы данных
# 
# - Если встречаются некорректные типы данных, предположите их причины.
# - При необходимости проведите преобразование типов данных. Помните, что столбцы с числовыми данными и пропусками нельзя преобразовать к типу `int64`. Сначала вам понадобится обработать пропуски, а затем преобразовать типы данных.

# - В числовых столбцах могут встретиться строковые значения, например `unknown` или другие. Приводите такие столбцы к числовому типу данных, заменив строковые значения на пропуски.

# In[10]:


# Уникальные значения по столбцам с несоответствием
unique_eu_sales = df['eu_sales'].unique()
unique_jp_sales = df['jp_sales'].unique()
unique_user_score = df['user_score'].unique()
unique_critic_score = df['critic_score'].unique()
unique_years = df['year_of_release'].unique()
unique_rating = df['rating'].unique()

display(unique_eu_sales)
display(unique_jp_sales)
display(unique_user_score)
display(unique_critic_score)
display(unique_years)
display(unique_rating)


# Требуется преобразовать 'Year of Release', 'EU sales', 'JP sales', 'User Score', там некорректные типы данных

# In[11]:



# Преобразование данных в числовой формат
df['year_of_release'] = pd.to_numeric(df['year_of_release'], errors='coerce').fillna(-1).astype('int64')
df['eu_sales'] = pd.to_numeric(df['eu_sales'], errors='coerce').fillna(-1).astype('float64')
df['jp_sales'] = pd.to_numeric(df['jp_sales'], errors='coerce').fillna(-1).astype('float64')
df['user_score'] = pd.to_numeric(df['user_score'], errors='coerce').fillna(-1).astype('float64')
df['critic_score'] = pd.to_numeric(df['critic_score'], errors='coerce').fillna(-1).astype('int64')
display(df)
df.info()

# Проверка структуры данных


# In[ ]:





# ### 2.3. Наличие пропусков в данных
# 
# - Посчитайте количество пропусков в каждом столбце в абсолютных и относительных значениях.
# 

# - Изучите данные с пропущенными значениями. Напишите промежуточный вывод: для каких столбцов характерны пропуски и сколько их. Предположите, почему пропуски могли возникнуть. Укажите, какие действия с этими данными можно сделать и почему.
# 

# In[12]:


# Подсчитываем количество пропусков в каждом столбце
missing_counts = df.isna().sum()

# Рассчитываем долю пропусков
missing_part = missing_counts / len(df)

# Создаем датафрейм с результатами
missing_data = pd.DataFrame({'Количество пропусков': missing_counts, 'Доля пропусков': missing_part})

# Выводим результаты
print(missing_data)


# Данные из пункта 1!!! Сейчас после преобразования данные изменились.
# 
# Самое большое количество пропусков хранится в столбцах 'Critic Score' - 51.4%, 'User Score' - 40.1%, 'Rating' - 40.5%. 
# В столбце year_of_release число пропусков менее 2%, этими данными по годам можно пренебречь и удалить их, они не повлияют на результат. В столбцах critic_score, user_score и rating пропущенные значения составляют 40-50%. Вероятно, это связано с тем, что данные игры не были популярны, практически не пользовались спросом. Пропуски в столбцах 'eu_sales', 'jp_sales', critic_score, user_score заполним средними значениями. 'Rating' заполнил значением no_rating

# - Обработайте пропущенные значения. Для каждого случая вы можете выбрать оптимальный, на ваш взгляд, вариант: заменить на определённое значение, оставить как есть или удалить.
# - Если вы решите заменить пропуски на значение-индикатор, то убедитесь, что предложенное значение не может быть использовано в данных.
# - Если вы нашли пропуски в данных с количеством проданных копий игры в том или ином регионе, их можно заменить на среднее значение в зависимости от названия платформы и года выхода игры.

# In[13]:


# заполним пропуски средним значением в 'eu_sales' и 'jp_sales' с помощью функции:
def fill_sales(series):
    return series.fillna(series.mean())

# Применяем функцию к нужным столбцам
df['eu_sales'] = fill_sales(df['eu_sales'])
df['jp_sales'] = fill_sales(df['jp_sales'])

# Заполняем пропуски значениями -1 для critic_score и user_score, для последующей категоризации
# Заполнение поля rating значением no_rating
df['rating'] = df['rating'].fillna('no_rating')  
df['critic_score'] = df['critic_score'].fillna(-1)
df['user_score'] = df['user_score'].fillna(-1)
df


# In[14]:


# Удаляем строки с пропусками в year_of_release. Ихвсего 275 штук
df = df[~df['year_of_release'].isna()]

# Выводим обновленный датафрейм
df


# ### 2.4. Явные и неявные дубликаты в данных
# 
# - Изучите уникальные значения в категориальных данных, например с названиями жанра игры, платформы, рейтинга и года выпуска. Проверьте, встречаются ли среди данных неявные дубликаты, связанные с опечатками или разным способом написания.
# - При необходимости проведите нормализацию данных с текстовыми значениями. Названия или жанры игр можно привести к нижнему регистру, а названия рейтинга — к верхнему.

# In[15]:


# Уникальные значения в категориальных данных
unique_genres = df['genre'].unique()
unique_platforms = df['platform'].unique()
unique_ratings = df['rating'].unique()
unique_years = df['year_of_release'].unique()

display(unique_genres)
display(unique_platforms)
display(unique_ratings)
display(unique_years)


# In[28]:


# Меняем регистр 
df['genre'] = df['genre'].str.lower()
df['platform'] = df['platform'].str.lower()
df['rating'] = df['rating'].str.upper()


# In[17]:


unique_combinations_count = df[['genre', 'platform', 'rating', 'year_of_release']].nunique()
# Выводим результат
display(f'Количество уникальных комбинаций жанр-платформа: {unique_combinations_count}')


# - После того как нормализуете данные и устраните неявные дубликаты, проверьте наличие явных дубликатов в данных.

# In[18]:


# Сортируем датафрейм по всем столбцам
df_sorted = df.sort_values(by=df.columns.tolist())

# Находим дубликаты
duplicates = df_sorted[df_sorted.duplicated(keep=False)]

# Выводим дубликаты
duplicates.head(10)


# In[19]:


# Определяем количество строк до удаления дубликатов
initial_row_count = len(df)
print(f'Количество строк до удаления дубликатов: {initial_row_count}')

# Находим дублирующиеся строки
duplicates = df[df.duplicated()]
print("Дублирующиеся строки:")
print(duplicates)

# Удаляем дублирующиеся строки
games_cleaned = df.drop_duplicates()

# Определяем количество строк после удаления дубликатов
final_row_count = len(games_cleaned)
print(f'Количество строк после удаления дубликатов: {final_row_count}')


# - Напишите промежуточный вывод: укажите количество найденных дубликатов и действия по их обработке.

# После обработки и нормализации данных были выведены строки до удаления дубликатов, найдены 241 явных дубликатов, они удалены.
# 

# Перед этим во время были удалены строки с пропущенными данными в year_of_release.

# In[ ]:





# - В процессе подготовки данных вы могли что-либо удалять, например строки с пропусками или ошибками, дубликаты и прочее. В этом случае посчитайте количество удалённых строк в абсолютном и относительном значениях.

# In[20]:


total_rows = 16956
final_row_count = 16956-241-275

deleted_rows = total_rows - final_row_count

deleted_share = round((deleted_rows / total_rows), 4)

display(deleted_rows)
display(deleted_share)


# In[ ]:





# - После проведения предобработки данных напишите общий промежуточный вывод.

# В процессе предобработки были удалены ячейки с пропущенным годом выпуска (275 штук), а также 241 явных дубликатов, 
# суммарно это 516 строк (3.04% от всех значений)
# 
# Доля ячеек с пропущенным годом выпуска: 275 / 16956 = 1.62%   
# Доля ячеек с явными дубликатами: 241 / 16956 = 1.42%

# Были проверены явные и неявные дубликаты. 
# Ячейки 'year_of_release' и 'critic_score' приведены к типу int64, ячейки 'eu_sales', 'jp_sales', 'user_score' к типу float64.
# Заполнены средние значения в 'eu_sales', 'jp_sales', а также -1 в 'user_score', 'critic_score', no_rating в rating.

# ---
# 
# ## 3. Фильтрация данных
# 
# Коллеги хотят изучить историю продаж игр в начале XXI века, и их интересует период с 2000 по 2013 год включительно. Отберите данные по этому показателю. Сохраните новый срез данных в отдельном датафрейме, например `df_actual`.

# In[21]:


df_actual = df.copy()
# Ставим диапазон от 2000 до 2013гг включительно
df_actual = df[(df['year_of_release'] >= 2000) & (df['year_of_release'] <= 2013)]

# Смотрим данные нового датафрейма
print(f'Количество строк в df_actual: {len(df_actual)}')
print(df_actual.info())


# После фильтрации осталось 12980 строк в указанном диапазоне

# In[22]:


# Всё это можно показать кодом (Смотри ниже)
 
 # код ревьюера
 # Создаем DataFrame
df_my = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})

# Давай его посмотрим
print('Вот так выглядит df_my изначально')
display(df_my)

# А теперь давай создадим "копию" DataFrame без использования .copy()
df_fake_copy = df_my


# А теперь вносим изменения в "копию"
df_fake_copy.loc[0, 'A'] = 100
print('Вот так выглядит df_fake_copy  после внесения изменений')
display(df_fake_copy)

# А теперь вопрос на засыпку, что произойдёт с df_my?

 
 
 # Смотрим
display(df_my)
# И оказывается что он принял все изменения df_fake_copy


# Но в чём тогда смысл df_copy = df_my, если изменения в одном, немедленно приведёт к изменениям в другом? 
# 
# Чтобы сделать настоящую копию:

df_real_copy = df_my.copy()

# И теперь если мы внесём изменения в df_real_copy, это не приведёт к изменениям в df_my, а если мы изменим df_my, 
# df_real_copyэто не приведёт к изменениям 

#  обрати на это внимание

# Почему так происходит .copy()? Python, объекты, такие как DataFrame, являются ссылочными типами данных. 
# Это означает, что переменные, которые хранят эти объекты, фактически хранят ссылки на место в памяти, 
# где находится объект. Давай посмотрим id df_my и id df_fake_copy
df_my_id = id(df_my)
df_fake_copy_id = id(df_fake_copy)

print(f"Смотрим сектора хранения информации df_my: {df_my_id} и df_fake_copy_id: {df_fake_copy_id}")

# И видим что они идентичные! То есть наши это фреймы по-прежнему ссылаются на один и тот же сектор
# Вот поэтому изменения в одном приводят к изменению в другом


# ---
# 
# ## 4. Категоризация данных
#     
# Проведите категоризацию данных:
# - Разделите все игры по оценкам пользователей и выделите такие категории: высокая оценка (от 8 до 10 включительно), средняя оценка (от 3 до 8, не включая правую границу интервала) и низкая оценка (от 0 до 3, не включая правую границу интервала).

# In[23]:




# Создаем столбец с категориями на основе пользовательских оценок
def user_category_score(score):
    if score >= 8 and score <= 10:
        return 'высокая'
    elif score >= 3 and score < 8:
        return 'средняя'
    elif score >= 0 and score < 3:
        return 'низкая'
    else:
        return 'не определено'

df['user_category'] = df['user_score'].apply(user_category_score)

# Выводим результат
df[['user_score', 'user_category']].head()


# In[ ]:





# - Разделите все игры по оценкам критиков и выделите такие категории: высокая оценка (от 80 до 100 включительно), средняя оценка (от 30 до 80, не включая правую границу интервала) и низкая оценка (от 0 до 30, не включая правую границу интервала).

# In[24]:



# Создаем столбец с категориями на основе оценок критиков
def critic_category_score(score):
    if score >= 80 and score <= 100:
        return 'высокая'
    elif score >= 30 and score < 80:
        return 'средняя'
    elif score >= 0 and score < 30:
        return 'низкая'
    else:
        return 'не определено'

df['critic_category'] = df['critic_score'].apply(critic_category_score)

# Выводим результат
df[['critic_score', 'critic_category']].head()


# In[ ]:





# In[ ]:





# - После категоризации данных проверьте результат: сгруппируйте данные по выделенным категориям и посчитайте количество игр в каждой категории.

# In[25]:


# Общее количество игр в разрезе оценки пользователя
total_by_user_score = df.groupby('user_category')['user_score'].count()
display('Общее количество игр по оценке пользователей:')
display(total_by_user_score)


# In[26]:


# Общее количество игр в разрезе оценки критика
total_by_critic_score = df.groupby('critic_category')['critic_score'].count()
display('Общее количество игр по оценке критиков:')
display(total_by_critic_score)


# - Выделите топ-7 платформ по количеству игр, выпущенных за весь актуальный период.

# In[27]:


platform_counts = df_actual['platform'].value_counts()

top7_platforms = platform_counts.head(7)
top7_platforms


# In[ ]:





# ---
# 
# ## 5. Итоговый вывод
# 
# В конце напишите основной вывод и отразите, какую работу проделали. Не забудьте указать описание среза данных и новых полей, которые добавили в исходный датасет.

# В проекте первоначально загрузили данные и ознакомились с ними. Выяснили исходные данные, количество строк и столбцов.
# Изучили долю пропусков в столбцах. Самое большое количество пропусков было в столбцах "оценка пользователя", "оценка критика" и "рейтинг" (40-50%).
# Год привел к целочисленному значению, оценку пользователей - к вещественному. Долю продаж в Японии и Европе - также к вещественному.
# Заменил пропуски в "оценка пользователя" и "оценка критика" на среднее значение для корректных расчетов, в поле "рейтинг" указал отсутствие рейтинга.
# Пропуски в поле "год" удалил, так как их доля менее 2% и они не сыграют существенную роль.
# Привел наименования столбцов и значения к нижнему регистру.
# Удалил явные дубликаты. Суммарно доля удаленных щначений составила 516 (3.04% от общего количества). Это 241 явных дубликатов и 275 полей с пропущенным годом.
# Были отфильрованы данные по годам выпуска с 2000 по 2013, также была проведена категоризация по оценкам пользователей и критиков, а также выведены топ-7 платформ по количеству игр.
# 
# 
# 

# Самое большое количество игр было на платформе PS2 (2154), чуть менее у DS (2146), далее Wii (1199).
# Абсолютное большинство игр получили средние оценки критиков (от 30 до 80) и оценки пользователей (от 3 до 8).
# Количество игр с 2000 по 2013 год составило 12980 штук (всего в таблице 16956).
# Доля удаленных строк составила 3% - это явные дубликаты и пропуски заполненных лет.
# В таблице представлены данные с 1980 по 2016 год (36 лет), при этом за проанализированные 13 лет (36% от количества взятых лет) было выпущено 76% игр (12980 / 16956).
# Это связано с бурным развитием компьютерных технологий и игр в период с 2000 по 2013 гг.
# 

# 

# In[ ]:




